{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Elastic Training Example using Azure Machine Learning Service\n",
    "This notebook contains an end-to-end walkthrough of Imagenet example using Azure Machine Learning service.\n",
    "\n",
    "Steps:\n",
    "* Get user credentials using Service Principal\n",
    "* Create Resource Group\n",
    "* Create IP Address\n",
    "* Create Vnet and Subnet\n",
    "* Create NIC\n",
    "* Create VM\n",
    "* Setup etcd on VM\n",
    "* Initialize an AzureML workspace\n",
    "* Register a datastore\n",
    "* Create an experiment\n",
    "* Provision a compute target\n",
    "* Create an Estimator\n",
    "* Configure and Run\n",
    "\n",
    "## Prerequisites\n",
    "* Azure Subscription\n",
    "* Azure Machine Learning workspace\n",
    "* Azure Management SDK\n",
    "* Azure Machine Learning SDK\n",
    "\n",
    "If you are using [Azure Compute Instance](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance), no additional setup is required. Otherwise you need to manually install the required SDK's \n",
    "* pip install azure-mgmt-network\n",
    "* pip install azure-mgmt-compute\n",
    "* pip install --upgrage azureml-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular python libraries\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# Azure libraries\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "from azure.mgmt.compute import ComputeManagementClient\n",
    "from azure.mgmt.network import NetworkManagementClient\n",
    "from azure.mgmt.compute.models import DiskCreateOption\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Account Information\n",
    "\n",
    "User's credentials are required to create the Azure Network, Compute resources for Pytorch Elastic Training. Instructions for generating tenant, client id and secret can be found at [portal](https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal), [CLI](https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?view=azure-cli-latest), [Powershell](https://docs.microsoft.com/en-us/powershell/azure/create-azure-service-principal-azureps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<subscription_id>\"\n",
    "resource_group = \"<Resource group name>\"\n",
    "region = \"<Resource group region>\"\n",
    "\n",
    "tenant = \"<app id>\"\n",
    "client_id = \"<client id>\"\n",
    "secret = \"<secret>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get users service principal credentials\n",
    "credentials = get_credentials(tenant, client_id, secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Resource Group\n",
    "Creates a resource group with the specified name if one doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a resource group if one doesn't exist\n",
    "resource_group_client = ResourceManagementClient(\n",
    "    credentials,\n",
    "    subscription_id\n",
    ")\n",
    "\n",
    "create_resource_group(resource_group_client, resource_group, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Setup\n",
    "Create a Public IP Address, Vnet, Subnet and NIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_client = NetworkManagementClient(\n",
    "    credentials,\n",
    "    subscription_id\n",
    ")\n",
    "\n",
    "ip_name = \"pet-test-ip\"\n",
    "vnet_name = \"pet-test-vnet\"\n",
    "subnet_name = \"pet-test-subnet\"\n",
    "nic_name = \"pet-test-nic\"\n",
    "ipconfig_name = \"pet-test-ipconfig\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network resource creation can be skipped if using existing resources. Make sure to correctly populate the ip_name, vnet_name, subnet_name, nic_name and ipconfig_name fields in the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_public_ip_address(network_client, resource_group, region, ip_name)\n",
    "\n",
    "create_vnet(network_client, resource_group, region, vnet_name)\n",
    "\n",
    "create_subnet(network_client, resource_group, vnet_name, subnet_name)\n",
    "\n",
    "create_nic(network_client, resource_group, region, vnet_name, subnet_name, ip_name, ipconfig_name, nic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VM setup\n",
    "Creates a ubuntu VM in the vnet created above and setup etcd to listen on port 2379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_client = ComputeManagementClient(\n",
    "    credentials,\n",
    "    subscription_id\n",
    ")\n",
    "\n",
    "vm_name = \"pet-test-vm\"\n",
    "vm_size = \"<Azure VM Size>\"\n",
    "\n",
    "# Create a VM for etcd\n",
    "create_vm(network_client, compute_client, resource_group, region, nic_name, vm_name, vm_size)\n",
    "\n",
    "# Run custom script extension to setup etcd\n",
    "setup_etcd(compute_client, resource_group, vm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learing Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AzureML libraries\n",
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace, Datastore, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "from azureml.core.runconfig import MpiConfiguration, RunConfiguration, DEFAULT_GPU_IMAGE\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AzureML Workspace setup\n",
    "If you are not running on [Azure Compute Instance](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance), please refer to the [Configuration Notebook](https://github.com/Azure/MachineLearningNotebooks/blob/56e0ebc5acb9614fac51d8b98ede5acee8003820/configuration.ipynb) on establishing connection to AzureML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = \"<Workspace name>\"\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    #ws.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datastore registration\n",
    "The following code assumes that the training data is already copied to Azure Blob storage with the following directory structure. It is recommened to retain this directory structure to run this notebook without code updates. In case the directory structure is different, the constructor of PyTorch estimator where the datastore is mounted should be modified.\n",
    "\n",
    "    data\n",
    "    |\n",
    "    |__train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the datastore with the workspace\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='<Blob store name>',\n",
    "                                             container_name='<container name>',\n",
    "                                             account_name=\"<Storage account name>\", \n",
    "                                             account_key=\"<Storage account key>\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the workspace attributes\n",
    "print('Datastore name: ' + ds.name, \n",
    "      'Container name: ' + ds.container_name, \n",
    "      'Datastore type: ' + ds.datastore_type, \n",
    "      'Workspace name: ' + ds.workspace.name, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Experiment\n",
    "Experiment is a logical container in AzureML workspace. It hosts run records which can include run metrics and output artifacts from your experiments. More information on Experiment can be found [here](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'pet-imagenet'\n",
    "pet_experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision Training cluster\n",
    "Create AzureML training cluster in the VNET created above. For information on AzureML compute, please read [this](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute).\n",
    "* Azure VM Size: VM family of nodes provisioned by AmlCompute.\n",
    "* min_nodes: Minimum number of nodes while running a job on AmlCompute\n",
    "* max_nodes: Maximum nodes to autoscale while running a job on AmlCompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the compute cluster\n",
    "pet_cluster_name = \"pet-test-cluster\" \n",
    "\n",
    "# Verify that the cluster doesn't exist already\n",
    "try:\n",
    "    pet_compute_target = ComputeTarget(workspace=ws, name=pet_cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='<Azure VM Size>',\n",
    "                                                          min_nodes=<min_nodes>,\n",
    "                                                          max_nodes=<max_nodes>,\n",
    "                                                          vnet_name=vnet_name,\n",
    "                                                          vnet_resourcegroup_name=resource_group,\n",
    "                                                          subnet_name=subnet_name)\n",
    "    \n",
    "    # create the cluster\n",
    "    pet_compute_target = ComputeTarget.create(ws, pet_cluster_name, compute_config)\n",
    "    pet_compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "#print(pet_compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator definition and run submission\n",
    "The estimator uses a custom docker image and main.py as the entry script for execution.\n",
    "For more information on Estimator, refer [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the project folder\n",
    "project_folder = '.' # This is to allow the libraries stored under pytorch/ to be loaded\n",
    "\n",
    "## Using a public image published on Azure.\n",
    "image_name = 'mcr.microsoft.com/azureml/elastic:pytorch-elastic-openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n",
    "\n",
    "# Define the Pytorch estimator\n",
    "pet_estimator = PyTorch(source_directory=project_folder,\n",
    "                    # Compute configuration\n",
    "                    compute_target=pet_compute_target,\n",
    "                    node_count=1, \n",
    "                    use_gpu=True,\n",
    "                    \n",
    "                    #Docker image\n",
    "                    use_docker=True,\n",
    "                    custom_docker_image=image_name,\n",
    "                    user_managed=True,\n",
    "                    \n",
    "                    # Training script parameters\n",
    "                    script_params = {\n",
    "                        # Required Params\n",
    "                        \"--input_path\" : ds.path('data/train/').as_mount()\n",
    "                    },\n",
    "                    \n",
    "                    entry_script='main.py',\n",
    "                    inputs=[ds.path('data/').as_mount()]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_estimator.run_config.environment.environment_variables = {\"RDZV_ENDPOINT\":\"10.0.0.4:2379\", \"ETCD_PROTOCOL\":\"http\",\"MIN_SIZE\":<min_nodes>, \"MAX_SIZE\":<max_nodes>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the run\n",
    "pet_run = pet_experiment.submit(pet_estimator)\n",
    "RunDetails(pet_run).show()"
   ]
  }
 ]
}